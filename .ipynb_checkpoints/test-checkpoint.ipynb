{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "default_padding='SAME'\n",
    "\n",
    "def layer(op):\n",
    "    def decorator(self,*args,**kwargs):\n",
    "        name=kwargs['name']\n",
    "\n",
    "        cur_input=self.input[0]\n",
    "        cur_output=op(self,cur_input,*args,**kwargs)\n",
    "        self.layers[name]=cur_output\n",
    "        self.feed(name)\n",
    "\n",
    "        return self\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self,input):\n",
    "        self.input=[]\n",
    "        self.layers=dict(input)\n",
    "        \n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        #必须被子类具体化\n",
    "        raise NotImplementedError('Must be subclassed')\n",
    "\n",
    "\n",
    "    def get_output(self,layer):\n",
    "        assert layer in self.layers.keys(),\"Invalid Keys\"\n",
    "        return self.layers[layer]\n",
    "\n",
    "    def feed(self,*args):\n",
    "        assert len(args)!=0\n",
    "\n",
    "        self.input=[]\n",
    "        for i in args:\n",
    "            self.input.append(self.layers[i])\n",
    "        return self\n",
    "\n",
    "    def make_var(self,name,shape,initializer):\n",
    "        return  tf.get_variable(name,shape,initializer=initializer)\n",
    "\n",
    "    @layer\n",
    "    def conv(self,input,k_w,k_h,c_o,s_w,s_h,name,relu=True,padding=default_padding):\n",
    "        c_i=input.get_shape()[-1]\n",
    "\n",
    "        convolve=lambda i,f: tf.nn.conv2d(i,f,[1,s_w,s_h,1],padding=padding)\n",
    "\n",
    "        with tf.variable_scope(name,reuse=tf.AUTO_REUSE) as scope:\n",
    "            init_weights=tf.truncated_normal_initializer(0.0,stddev=0.01)\n",
    "            init_biases=tf.constant_initializer(0.0)\n",
    "            filters=self.make_var(\"weights\",[k_w,k_h,c_i,c_o],init_weights)\n",
    "            biases=self.make_var(\"biases\",[c_o],init_biases)\n",
    "\n",
    "            output=convolve(input,filters)\n",
    "\n",
    "            if relu:\n",
    "                biases=tf.nn.bias_add(output,biases)\n",
    "                return tf.nn.relu(biases,name=scope.name)\n",
    "            else:\n",
    "                return tf.nn.bias_add(output,biases,name=scope.name)\n",
    "    @layer\n",
    "    def max_pool(self,input,k_w,k_h,s_w,s_h,name,padding=default_padding):\n",
    "        return tf.nn.max_pool(input,ksize=[1,k_h,k_w,1],\n",
    "                              strides=[1,s_h,s_w,1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "    @layer\n",
    "    def reshape(self,input,name):\n",
    "        output=tf.reshape(input,[input.get_shape()[0],-1],name=name)\n",
    "        return output\n",
    "\n",
    "    @layer\n",
    "    def fc(self,input,o_dim,name,relu=True):\n",
    "        with tf.variable_scope(name,reuse=tf.AUTO_REUSE) as scope:\n",
    "            input_shape=input.get_shape()\n",
    "            feed_in, dim = (input, input_shape[-1])\n",
    "            init_weights = tf.truncated_normal_initializer(0.0, stddev=0.01)\n",
    "            init_biases = tf.constant_initializer(0.0)\n",
    "\n",
    "            weights = self.make_var('weights', [dim, o_dim], init_weights)\n",
    "            biases = self.make_var('biases', [o_dim], init_biases)\n",
    "\n",
    "            op=tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n",
    "            return op(feed_in,weights,biases,name=scope.name)\n",
    "\n",
    "    @layer\n",
    "    def softmax(self,input,name):\n",
    "        return tf.nn.softmax(input,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Vgg16_train(Network):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.input=[]\n",
    "        self.data=tf.placeholder(tf.float32,shape=[2,224,224,3])\n",
    "        self.labels=tf.placeholder(tf.float32,shape=[2,1])\n",
    "        self.layers={'data':self.data,'labels':self.labels}\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        (self.feed('data')\n",
    "             .conv(3,3,64,1,1,name='conv1_1')\n",
    "             .conv(3,3,64,1,1,name='conv1_2')\n",
    "             .max_pool(2,2,2,2,name='pool1',padding='VALID')\n",
    "             .conv(3,3,128,1,1,name='conv2_1')\n",
    "             .conv(3,3,128,1,1,name='conv2_2')\n",
    "             .max_pool(2,2,2,2,name='pool2',padding='VALID')\n",
    "             .conv(3,3,256,1,1,name='conv3_1')\n",
    "             .conv(3,3,256,1,1,name='conv3_2')\n",
    "             .conv(3,3,256,1,1,name='conv3_3')\n",
    "             .max_pool(2,2,2,2,name='pool3',padding='VALID')\n",
    "             .conv(3,3,512,1,1,name='conv4_1')\n",
    "             .conv(3,3,512,1,1,name='conv4_2')\n",
    "             .conv(3,3,512,1,1,name='conv4_3')\n",
    "             .max_pool(2,2,2,2,name='pool4',padding='VALID')\n",
    "             .conv(3,3,512,1,1,name='conv5_1')\n",
    "             .conv(3,3,512,1,1,name='conv5_2')\n",
    "             .conv(3,3,512,1,1,name='conv5_3')\n",
    "             .max_pool(2,2,2,2,name='pool5',padding='VALID')\n",
    "             .reshape(name='reshape6')\n",
    "             .fc(4096,name='fc6')\n",
    "             .fc(4096,name='fc7')\n",
    "             .fc(2622,name='fc8',relu=False)\n",
    "             .softmax(name='cls_prob'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f49f7ed7160>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage.io as skii\n",
    "img=skii.imread(\"Aamir_Khan_March_2015.jpg\")\n",
    "img_test=img[:224,:224,:]\n",
    "skii.imshow(img_test)\n",
    "skii.show()\n",
    "# img_test=np.vstack((img_test,img_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=np.array([[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_test=img_test.reshape(-1,224,224,3)\n",
    "labels=labels.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2622)\n"
     ]
    }
   ],
   "source": [
    "vgg=Vgg16_train()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cls=vgg.get_output('cls_prob')\n",
    "    feed_dict={vgg.data:img_test,vgg.labels:labels}\n",
    "    cls_pro=sess.run(cls,feed_dict=feed_dict)\n",
    "    print(cls_pro.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.GradientDescentOptimizer"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
